////  MemoryDetailView.swift//  MemoirAI////  Created by user941803 on 4/29/25.//import SwiftUIimport UIKitimport AVFoundationimport PhotosUIimport Speech  // ← newstruct MemoryDetailView: View {    @Environment(\.presentationMode) private var presentationMode    @Environment(\.managedObjectContext) private var context    // ← needed to save transcript    let memory: MemoryEntry    @State private var audioPlayer: AVAudioPlayer?    @State private var isPlaying = false    @State private var isTranscribing = false            // ← new    @State private var transcriptText: String? = nil      // ← new    @State private var photoItems: [PhotosPickerItem] = []    @State private var images: [UIImage] = []    @State private var isLoadingImage = false    @State private var photoError: String?    @State private var isEditing = false    @State private var draftText: String = ""    private let backgroundColor = Color(red: 1.0, green: 0.96, blue: 0.89)    private let cardColor       = Color(red: 0.98, green: 0.93, blue: 0.80)    private let headerColor     = Color(red: 0.07, green: 0.21, blue: 0.13)    var body: some View {        ScrollView {            VStack(spacing: 24) {                // Centered prompt header                Text(memory.prompt ?? "")                    .font(.custom("Georgia-Bold", size: 22))                    .foregroundColor(headerColor)                    .multilineTextAlignment(.center)                    .fixedSize(horizontal: false, vertical: true)                    .padding(.horizontal, 24)                // Main content card                VStack(spacing: 20) {                    // Date                    if let date = memory.createdAt {                        Text(dateFormatted(date))                            .font(.custom("Georgia-Bold", size: 22))                            .foregroundColor(.black)                    }                    // Audio playback button                    if let audioURL = memory.audioFileURL,                       let url = URL(string: audioURL) {                        Button {                            togglePlayback(url: url)                        } label: {                            Image(systemName: isPlaying                                  ? "pause.circle.fill"                                  : "play.circle.fill")                                .resizable()                                .frame(width: 64, height: 64)                                .foregroundColor(.orange)                        }                        Text("Tap to listen to this memory")                            .font(.custom("Georgia", size: 16))                            .foregroundColor(.black)                        Divider()                        // ← New transcription UI                        if isTranscribing {                            ProgressView("Transcribing…")                                .padding(.vertical, 8)                        } else if let text = transcriptText {                            Text(text)                                .font(.custom("Georgia", size: 18))                                .multilineTextAlignment(.leading)                                .foregroundColor(.black)                                .lineSpacing(4)                                .padding(.vertical, 8)                        } else {                            // if there's already saved memory.text, show it                            if let saved = memory.text, !saved.isEmpty {                                Text(saved)                                    .font(.custom("Georgia", size: 18))                                    .multilineTextAlignment(.leading)                                    .foregroundColor(.black)                                    .lineSpacing(4)                                    .padding(.vertical, 8)                            }                        }                        Divider()                    }                    // Transcript / editor (user-editable)                    Group {                        if isEditing {                            TextEditor(text: $draftText)                                .font(.custom("Georgia", size: 18))                                .frame(minHeight: 120)                                .overlay(                                    RoundedRectangle(cornerRadius: 12)                                        .stroke(Color.gray.opacity(0.3), lineWidth: 1)                                )                        }                    }                    .onAppear { draftText = memory.text ?? "" }                    Divider()                    // Photo error/loading states                    if let error = photoError {                        Text(error)                            .font(.caption)                            .foregroundColor(.red)                        Button("Retry") {                            photoError = nil                            images.removeAll()                            loadPhotos()                        }                    }                    if isLoadingImage {                        ProgressView()                    }                    // Photo gallery header                    Text("Photos")                        .font(.subheadline)                        .textCase(.uppercase)                        .foregroundColor(.gray)                        .frame(maxWidth: .infinity, alignment: .leading)                    // Photo gallery                    GalleryView(                        images: $images,                        photoItems: $photoItems,                        pickAction: loadPhotos                    )                }                .padding()                .background(cardColor)                .cornerRadius(32)                .shadow(color: Color.black.opacity(0.06), radius: 4, x: 0, y: 4)                .padding(.horizontal, 24)                Spacer(minLength: 24)            }            .onAppear(perform: maybeTranscribe)   // ← kick off transcription        }        .background(backgroundColor.ignoresSafeArea())        .navigationBarBackButtonHidden(true)        .toolbar {            ToolbarItem(placement: .navigationBarLeading) {                Button {                    presentationMode.wrappedValue.dismiss()                } label: {                    Image(systemName: "chevron.left")                        .font(.system(size: 18, weight: .medium))                        .foregroundColor(.black)                }            }            ToolbarItemGroup(placement: .navigationBarTrailing) {                Button(action: shareMemory) {                    Image(systemName: "square.and.arrow.up")                }                Button {                    isEditing.toggle()                } label: {                    Image(systemName: isEditing ? "checkmark" : "pencil")                }            }        }    }    private func maybeTranscribe() {        // only if we haven’t already saved or loaded text        guard transcriptText == nil,              (memory.text ?? "").isEmpty,              let urlString = memory.audioFileURL,              let fileURL = URL(string: urlString)        else { return }        SFSpeechRecognizer.requestAuthorization { authStatus in            guard authStatus == .authorized else { return }            DispatchQueue.main.async {                isTranscribing = true            }            let request = SFSpeechURLRecognitionRequest(url: fileURL)            SFSpeechRecognizer()?.recognitionTask(with: request) { result, error in                if let error = error {                    print("Transcription error:", error)                    DispatchQueue.main.async { isTranscribing = false }                } else if let result = result, result.isFinal {                    let text = result.bestTranscription.formattedString                    DispatchQueue.main.async {                        transcriptText = text                        memory.text = text                        try? context.save()                        isTranscribing = false                    }                }            }        }    }    private func loadPhotos() {        isLoadingImage = true        Task {            defer { isLoadingImage = false }            do {                images.removeAll()                for item in photoItems {                    if let data = try await item.loadTransferable(type: Data.self),                       let ui   = UIImage(data: data) {                        images.append(ui)                    }                }                photoError = nil            } catch {                photoError = "Failed to load images."            }        }    }    private func shareMemory() {        var items: [Any] = []        if let text = memory.text { items.append(text) }        if let urlString = memory.audioFileURL,           let url = URL(string: urlString) {            items.append(url)        }        items.append(contentsOf: images)        let av = UIActivityViewController(activityItems: items, applicationActivities: nil)        if let scene = UIApplication.shared.connectedScenes.first as? UIWindowScene,           let root  = scene.windows.first?.rootViewController {            root.present(av, animated: true)        }    }    private func togglePlayback(url: URL) {        do {            if isPlaying { audioPlayer?.stop() }            else {                audioPlayer = try AVAudioPlayer(contentsOf: url)                audioPlayer?.play()            }            isPlaying.toggle()        } catch {            print("Failed to play audio:", error)        }    }    private func dateFormatted(_ date: Date) -> String {        let fmt = DateFormatter()        fmt.dateStyle = .long        return fmt.string(from: date)    }}struct MemoryDetailView_Previews: PreviewProvider {    static var previews: some View {        let sample = MemoryEntry(            context: PersistenceController.preview.container.viewContext        )        sample.prompt        = "What did a normal day look like when you were seven years old?"        sample.text          = "I used to wake up early and…"        sample.createdAt     = Date()        sample.audioFileURL  = nil        return NavigationView {            MemoryDetailView(memory: sample)        }    }}