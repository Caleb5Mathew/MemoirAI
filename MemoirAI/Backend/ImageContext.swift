import Foundationimport UIKitactor ImageContext {    private let openAI: OpenAIImageService    func faceDescriptor(fileID: String, jpegData: Data? = nil) async throws -> String {        // ‚ñ∫ If we already have the JPEG bytes, use a data: URI; otherwise fall        //   back to the internal file-id scheme. Passing the JPEG avoids all        //   download / permission issues.        let imageURL: String        if let bytes = jpegData {            imageURL = "data:image/jpeg;base64,\(bytes.base64EncodedString())"        } else {            imageURL = "openai://file/\(fileID)"         // requires OpenAI fetch        }        var req = URLRequest(url: URL(string: "https://api.openai.com/v1/chat/completions")!)        req.httpMethod = "POST"        req.addValue("Bearer \(openAI.apiKey)",  forHTTPHeaderField: "Authorization")        req.addValue("application/json",         forHTTPHeaderField: "Content-Type")        let bodyDict: [String: Any] = [            "model": "gpt-4o-mini",            "messages": [[                "role": "user",                "content": [                    [                        "type": "text",                        "text": "Describe permanent appearance traits (race/ethnicity, skin-tone, hair colour & texture) in ONE short comma-separated sentence. No extra words."                    ],                    [                        "type": "image_url",                        "image_url": ["url": imageURL]                    ]                ]            ]],            "max_tokens": 32,            "temperature": 0        ]        let bodyData = try JSONSerialization.data(withJSONObject: bodyDict)        req.httpBody = bodyData        print("üì§ Vision body (first 300 chars):",              String(data: bodyData.prefix(300), encoding: .utf8) ?? "<binary>")        let (data, rsp) = try await openAI.session.data(for: req)        if let http = rsp as? HTTPURLResponse {            print("üì• Vision HTTP \(http.statusCode) headers:", http.allHeaderFields)        }        print("üñºÔ∏è Vision JSON raw:\n", String(data: data, encoding: .utf8) ?? "<binary>")        guard            let root    = try? JSONSerialization.jsonObject(with: data) as? [String: Any],            let choices = root["choices"] as? [[String: Any]],            let msg     = choices.first?["message"] as? [String: Any],            let text    = msg["content"] as? String,            !text.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty        else {            throw NSError(domain: "MemoirAI",                          code: -42,                          userInfo: [NSLocalizedDescriptionKey: "Vision descriptor empty / bad JSON"])        }        print("‚úÖ Final descriptor:", text)        return text.trimmingCharacters(in: .whitespacesAndNewlines)    }    func createReference(from image: UIImage) async throws -> (id: String, jpeg: Data) {        guard let jpg = image.jpegData(compressionQuality: 0.9) else {            throw NSError(domain: "MemoirAI",                          code: -1,                          userInfo: [NSLocalizedDescriptionKey: "JPEG-encode failed"])        }        var req = URLRequest(url: URL(string: "https://api.openai.com/v1/files")!)        req.httpMethod = "POST"        req.addValue("Bearer \(openAI.apiKey)", forHTTPHeaderField: "Authorization")        let boundary = UUID().uuidString        req.addValue("multipart/form-data; boundary=\(boundary)", forHTTPHeaderField: "Content-Type")        var body = Data()        // purpose        body.append("--\(boundary)\r\n".data(using: .utf8)!)        body.append("Content-Disposition: form-data; name=\"purpose\"\r\n\r\nvision\r\n".data(using: .utf8)!)        // file        body.append("--\(boundary)\r\n".data(using: .utf8)!)        body.append("Content-Disposition: form-data; name=\"file\"; filename=\"headshot.jpg\"\r\n".data(using: .utf8)!)        body.append("Content-Type: image/jpeg\r\n\r\n".data(using: .utf8)!)        body.append(jpg)        body.append("\r\n--\(boundary)--\r\n".data(using: .utf8)!)        req.httpBody = body        print("üì§ Uploading head-shot (\(jpg.count) bytes)‚Ä¶")        let (data, rsp) = try await openAI.session.data(for: req)        if let http = rsp as? HTTPURLResponse {            print("üì• Upload HTTP \(http.statusCode) headers:", http.allHeaderFields)        }        print("üîÑ Upload response raw:", String(data: data, encoding: .utf8) ?? "<binary>")        guard            let root = try? JSONSerialization.jsonObject(with: data) as? [String: Any],            let id   = root["id"] as? String        else {            throw NSError(domain: "MemoirAI",                          code: -2,                          userInfo: [NSLocalizedDescriptionKey: "Upload JSON missing id"])        }        return (id, jpg)          // ‚Üê return JPEG bytes so caller can inline if desired    }    init(apiKey: String, session: URLSession = .shared) {        print("[ImageContext] init")        self.openAI = OpenAIImageService(apiKey: apiKey, session: session)    }    func enrichPrompts(prompts: [ImagePrompt], withPhotos photos: [UIImage]) async throws -> [ImagePrompt] {        // ‚Ä¶ your existing enrichment code ‚Ä¶        return prompts    }}struct ImagePrompt: Identifiable, Hashable {    let id = UUID()    let text: String    let referenceImageIDs: [String]}