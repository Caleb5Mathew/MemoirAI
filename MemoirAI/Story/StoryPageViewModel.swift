////  StoryPageViewModel.swift//  MemoirAI////  Created by user941803 on 5/10/25.//  Updated 5/12/25 to fix argument labels and batch image call.//  Further updated 5/14/25 to integrate per-page progress and single-prompt image calls.//  Fixed type mismatch for StoryPageContent and ImagePrompt.//  Updated 5/15/25 to use combinedImagePrompt and remove MARKs.//import SwiftUIimport CoreData@MainActorclass StoryPageViewModel: ObservableObject {        @Published var isLoading = false    @Published var errorMessage: String?    @Published var images: [UIImage] = []    @Published var progress: Double = 0.0   // 0.0 … 1.0        // To store the full content (image prompt + page text) from PromptGenerator    @Published var storyContents: [StoryPageContent] = []        @AppStorage("memoirPageCount") private var pageCountSetting: Int = 2 // Default to 2 for easier testing    @AppStorage("memoirArtStyle") private var selectedArtStyleRawValue: String = ArtStyle.realistic.rawValue // Ensure ArtStyle enum is defined    @AppStorage("memoirCustomArtStyleText") private var customArtStyleText: String = ""        private var currentArtStyle: ArtStyle { // Ensure ArtStyle enum is defined        ArtStyle(rawValue: selectedArtStyleRawValue) ?? .realistic    }            private let promptGen: PromptGenerator // Ensure PromptGenerator class/struct is defined    private let imageCtx: ImageContext     // Ensure ImageContext class/struct is defined    private let imageSvc: OpenAIImageService // Ensure OpenAIImageService class/struct is defined            init() {        print("[StoryPageViewModel DEBUG] Initializing…")        // IMPORTANT: Replace this key or use your Info.plist method in production.        let key = "YOUR_API_KEY_HERE" // Replace with your actual key loading mechanism or key                if key.isEmpty || key == "YOUR_API_KEY_HERE" { // Simple check for placeholder            print("[StoryPageViewModel WARNING] Using placeholder or potentially invalid API Key. Ensure a real key is set for actual API calls.")        }                self.promptGen = PromptGenerator(apiKey: key)        self.imageCtx  = ImageContext(apiKey: key)        self.imageSvc  = OpenAIImageService(apiKey: key)                print("[StoryPageViewModel DEBUG] Loaded settings → pageCount: \(pageCountSetting), artStyle: \(currentArtStyle.rawValue), customText: '\(customArtStyleText.isEmpty ? "none" : customArtStyleText)'")    }    /// Returns the number of pages the user intends to generate based on current settings.    func expectedPageCount() -> Int {        print("[StoryPageViewModel] expectedPageCount called. Returning: \(self.pageCountSetting)")        return self.pageCountSetting    }            /// Generates the storybook for a profile, page by page, updating `progress`.    func generateStorybook(forProfileID profileID: UUID) async {        print("[StoryPageViewModel] generateStorybook called for profileID: \(profileID.uuidString)")        let currentPageCount = self.pageCountSetting        print("[StoryPageViewModel]   Using Page Count from settings: \(currentPageCount)")        print("[StoryPageViewModel]   Using Art Style from settings: \(currentArtStyle.rawValue), Custom Details: '\(customArtStyleText.isEmpty ? "none" : customArtStyleText)'")                isLoading = true        errorMessage = nil        images = []        storyContents = []        progress = 0.0                defer {            isLoading = false            print("[StoryPageViewModel] Generation complete (isLoading set to false)")        }                do {            let transcript = try await fetchFullTranscript(forProfileID: profileID)            guard !transcript.isEmpty else {                throw NSError(domain: "StoryPageViewModel", code: 2, userInfo: [NSLocalizedDescriptionKey: "No recorded memories for this profile. Record some first."])            }                        let rawStoryContents = try await promptGen.generatePrompts(                from: transcript, pageCount: currentPageCount, chosenArtStyle: currentArtStyle, customArtStyleDetails: customArtStyleText            )            self.storyContents = rawStoryContents            print("[StoryPageViewModel DEBUG] Step 2: StoryPageContent items received. Count: \(rawStoryContents.count)")            guard !rawStoryContents.isEmpty else {                throw NSError(domain: "StoryPageViewModel", code: 3, userInfo: [NSLocalizedDescriptionKey: "AI failed to generate any content. Try adjusting settings or transcript."])            }            let imagePromptsForProcessing = rawStoryContents.map { ImagePrompt(text: $0.imagePromptText) }            print("[StoryPageViewModel DEBUG] Derived \(imagePromptsForProcessing.count) ImagePrompts for enrichment/generation.")                        let userPhotos = await fetchPhotosForProfile(profileID)            let enrichedImagePrompts = try await imageCtx.enrichPrompts(prompts: imagePromptsForProcessing, withPhotos: userPhotos)            print("[StoryPageViewModel DEBUG] Step 3: ImagePrompts enriched. Count: \(enrichedImagePrompts.count)")                        var generatedImagesContainer: [UIImage] = []            let actualPromptsToProcess = enrichedImagePrompts.count            guard actualPromptsToProcess > 0 else {                print("[StoryPageViewModel WARNING] No enriched prompts to process for images.")                self.progress = 1.0                return            }            guard actualPromptsToProcess == storyContents.count else {                print("[StoryPageViewModel ERROR] Mismatch between enriched prompts count (\(actualPromptsToProcess)) and story contents count (\(storyContents.count)).")                throw NSError(domain: "StoryPageViewModel", code: 4, userInfo: [NSLocalizedDescriptionKey: "Internal data inconsistency between prompts and story content."])            }            for (index, singleImagePrompt) in enrichedImagePrompts.enumerated() {                print("[StoryPageViewModel DEBUG] Generating image for enriched prompt \(index+1) of \(actualPromptsToProcess): \"\(singleImagePrompt.text.prefix(50))...\"")                                let sceneDesc = singleImagePrompt.text                let rawCaption = storyContents[index].pageDisplayText                let caption = rawCaption.split(separator: "\n").joined(separator: " ")                let finalPromptText = PromptTemplates.combinedImagePrompt(sceneDescription: sceneDesc, caption: caption)                print("[StoryPageViewModel DEBUG] 🔍 FINAL DALL·E PROMPT:\n\(finalPromptText)")                                let combinedPrompt = ImagePrompt(text: finalPromptText)                // *** CORRECTED LOGIC HERE assuming generateImages returns [UIImage] ***                let batchResult = try await imageSvc.generateImages(from: [combinedPrompt])                                if let img = batchResult.first { // Check if the array is not empty and get the first UIImage                    generatedImagesContainer.append(img)                } else {                    print("[StoryPageViewModel WARNING] Image generation for prompt \(index+1) returned an empty array or failed. Appending a placeholder.")                    if let placeholderImage = UIImage(systemName: "exclamationmark.triangle.fill")?.withTintColor(.systemGray, renderingMode: .alwaysOriginal) {                        generatedImagesContainer.append(placeholderImage)                    }                }                // *** END OF CORRECTION ***                                progress = Double(index + 1) / Double(actualPromptsToProcess)                print("[StoryPageViewModel] Progress: \(Int(progress * 100))%")            }            self.images = generatedImagesContainer            print("[StoryPageViewModel DEBUG] Step 4: UIImages generated. Final count for self.images: \(self.images.count)")                        if self.images.count != actualPromptsToProcess {                 print("[StoryPageViewModel WARNING] Final image count (\(self.images.count)) does not match processed prompt count (\(actualPromptsToProcess)). Some images might be placeholders.")            }                    } catch {            print("[StoryPageViewModel ERROR] \(error.localizedDescription)")            if self.errorMessage == nil { self.errorMessage = error.localizedDescription }        }    }        private func fetchFullTranscript(forProfileID profileID: UUID) async throws -> String {        print("[StoryPageViewModel DEBUG] fetchFullTranscript called for profileID: \(profileID.uuidString).")        let container = PersistenceController.shared.container        let ctx = container.viewContext                return try await ctx.perform {            guard let memoryEntityDescription = NSEntityDescription.entity(forEntityName: "MemoryEntry", in: ctx) else {                print("[StoryPageViewModel DEBUG] 'MemoryEntry' entity not found. Using mock transcript.")                return "Mocked transcript because 'MemoryEntry' entity is not set up for profile \(profileID.uuidString)."            }            let req: NSFetchRequest<MemoryEntry> = MemoryEntry.fetchRequest()            req.entity = memoryEntityDescription            req.predicate = NSPredicate(format: "profileID == %@", profileID as CVarArg)            req.sortDescriptors = [NSSortDescriptor(keyPath: \MemoryEntry.createdAt, ascending: true)]                        let entries: [MemoryEntry]            do {                entries = try ctx.fetch(req)            } catch {                print("[StoryPageViewModel ERROR] Failed to fetch MemoryEntry: \(error)")                throw error            }            print("[StoryPageViewModel DEBUG] Fetched \(entries.count) memory entries for \(profileID.uuidString).")            if entries.isEmpty {                print("[StoryPageViewModel DEBUG] No MemoryEntry for \(profileID.uuidString). Returning empty transcript.")                return ""            }            let texts = entries.compactMap { $0.text?.trimmingCharacters(in: .whitespacesAndNewlines) }            let joinedTranscript = texts.joined(separator: "\n\n")            print("[StoryPageViewModel DEBUG] Joined transcript length for \(profileID.uuidString): \(joinedTranscript.count)")            return joinedTranscript        }    }        private func fetchPhotosForProfile(_ profileID: UUID) async -> [UIImage] {        print("[StoryPageViewModel DEBUG] fetchPhotosForProfile for \(profileID.uuidString) (Placeholder - returning empty).")        return []    }}// Ensure these supporting types are defined:// - struct StoryPageContent { let imagePromptText: String; let pageDisplayText: String }// - enum ArtStyle: String, CaseIterable { case realistic ... }// - struct PromptGenerator { ... }// - struct ImageContext { ... }// - struct OpenAIImageService { func generateImages(from prompts: [ImagePrompt]) async throws -> [UIImage] } // Assumed [UIImage]// - struct ImagePrompt { let text: String }// - enum PromptTemplates { static func combinedImagePrompt(...) -> String }// - class PersistenceController { static let shared ... }// - class MemoryEntry: NSManagedObject { ... }